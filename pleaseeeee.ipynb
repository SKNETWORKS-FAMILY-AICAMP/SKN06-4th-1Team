{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f0151-5f35-46bb-8e54-030985fcb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from collections import Counter\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from module.file import load_json, save_json\n",
    "from better_profanity import profanity\n",
    "from langchain_chroma import Chroma \n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "from langchain.schema import Document, AIMessage, HumanMessage\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory, RunnableLambda\n",
    "from langchain.schema import HumanMessage\n",
    "from operator import itemgetter\n",
    "from textwrap import dedent\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20724f-0115-4651-855e-7af3cf38696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(path: str, file_name: str, data: list):\n",
    "    \"\"\"\n",
    "    데이터를 pickle 파일로 저장.\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    with open(f\"{path}/{file_name}\", \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_pickle(path: str) -> list:\n",
    "    \"\"\"\n",
    "    pickle 파일에서 데이터 불러오기.\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_json(path: str, file_name: str, data: list):\n",
    "    \"\"\"\n",
    "    데이터를 json 파일로 저장.\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)  # path로 디렉토리 생성\n",
    "    full_path = os.path.join(path,file_name)  # file_path 생성\n",
    "    with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def load_json(path: str) -> list:\n",
    "    \"\"\"\n",
    "    json 파일에서 데이터 불러오기.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_ids_with_state(page_num: int, url: str) -> list:\n",
    "    \"\"\"\n",
    "    청년 정책의 ID 수집.\n",
    "    Parameters:\n",
    "        page_num (int): 추출하려는 총 페이지 수\n",
    "        url (str): 추출 대상의 페이지 링크를 조합할 베이스 링크\n",
    "    Returns:\n",
    "        policy_id_list (list): 상시, 진행중인 정책의 ID를 list로 모아 반환합니다.\n",
    "    \"\"\"\n",
    "    policy_id_list = []\n",
    "    for i in range(1, page_num + 1):\n",
    "        response = requests.get(f\"{url}{i}\")\n",
    "        soup = bs(response.text, \"lxml\")\n",
    "        \n",
    "        badges = soup.select(\"div.badge\")\n",
    "        titles = soup.select(\"a.tit\")\n",
    "        organ = soup.select(\"div.organ-name\")\n",
    "        \n",
    "        for j in range(len(titles)):\n",
    "            badge = badges[j].find(\"span\", attrs={\"label\"}).text\n",
    "            if badge in [\"진행중\", \"상시\"]:\n",
    "                policy_id = titles[j].attrs[\"id\"].replace(\"dtlLink_\", \"\")\n",
    "                organ_name = re.sub(r\"<.*?>\", \"\", str(organ[j].select_one(\"p\")))\n",
    "                organ_name = \"세종\" if organ_name == \"세종 세종\" else organ_name\n",
    "                if policy_id not in policy_id_list:\n",
    "                    policy_id_list.append([policy_id, organ_name])\n",
    "    \n",
    "    return policy_id_list\n",
    "\n",
    "def formated(string: str) -> str:\n",
    "    \"\"\"\n",
    "    HTML 태그, 이스케이프 문자, 과도한 공백 제거.\n",
    "    \"\"\"\n",
    "    tag_format = r\"<.*?>\"\n",
    "    string = string.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    string = re.sub(tag_format, \"\", str(string))\n",
    "    string = string.replace(\"  \", \"\")\n",
    "    return string\n",
    "\n",
    "def crawling(policy_id_list: list, url: str, params: dict, cont_attrs: bool = True) -> list:\n",
    "    \"\"\"\n",
    "    정책 상세 정보를 수집.\n",
    "    \"\"\"\n",
    "    total_policy = []\n",
    "    format = {\"br\": r\"<br/>\", \"a\": r\"<a href\"}\n",
    "    \n",
    "    for id, organ in policy_id_list:\n",
    "        policy = {}\n",
    "        try:\n",
    "            response = requests.get(f\"{url}{id}\")\n",
    "        except:\n",
    "            response = requests.get(f\"{url.replace('https', 'http')}{id}\")\n",
    "        \n",
    "        soup = bs(response.text, \"html.parser\")\n",
    "\n",
    "        # 정책 이름 추출\n",
    "        title = soup.find(params[\"title\"][0], params[\"title\"][1]).text\n",
    "        policy[\"정책 이름\"] = title\n",
    "        \n",
    "        if cont_attrs:\n",
    "            policy[\"기관\"] = organ\n",
    "            subtitle = soup.find(\"p\", \"doc_desc\").text\n",
    "            subtitle = subtitle.replace(\"\\r\", \" \")\n",
    "            subtitle = subtitle.strip()\n",
    "            policy[\"요약\"] = subtitle\n",
    "            list_tit = soup.find_all(\n",
    "                name=params[\"list_tit\"][0], attrs=params[\"list_tit\"][1]\n",
    "            )\n",
    "            list_cont = soup.find_all(\n",
    "                name=params[\"list_cont\"][0], attrs=params[\"list_cont\"][1]\n",
    "            )\n",
    "        else:\n",
    "            list_tit = soup.find_all(name=params[\"list_tit\"][0])\n",
    "            list_cont = soup.find_all(name=params[\"list_cont\"][0])\n",
    "        \n",
    "        # 항목 내용 처리\n",
    "        for i in range(len(list_tit)):\n",
    "            # list_cont[i].contents = [\"\\n\", \"ㅁㅁㅁ\", \"\\n\"] 또는 [\"\\n\\t\\t\\t\\tㅁㅁㅁㅁ\\n\\t\\t\\t\\t\", \"<br/>\", \"ㅁㅁㅁ\"]과 같이 나옴\n",
    "            if len(list_cont[i].contents) > 1:\n",
    "                contents = []\n",
    "                for j in range(len(list_cont[i].contents)):\n",
    "                    content = list_cont[i].contents[j]\n",
    "                    # <br/> 제거\n",
    "                    if re.match(format[\"br\"], str(content)) != None:\n",
    "                        content = None\n",
    "                    # url만 있는 경우 추출\n",
    "                    elif re.match(format[\"a\"], str(content)) != None:\n",
    "                        content = content.attrs[\"href\"]\n",
    "                    # 그 외 공백 제거, '\\n', '\\t', 제거 안된 html 태그 제거\n",
    "                    else:\n",
    "                        content = content.text\n",
    "                        content = content.strip()\n",
    "                        content = formated(content)\n",
    "                    # 처리 작업이 끝난 후 의미있는 요소만 contents(list)에 추가\n",
    "                    if content not in [None, \"\\n\", \"\", \",\"]:\n",
    "                        # \\r이 있을 경우 이를 구분자로 분할한 뒤 삽입\n",
    "                        if \"\\r\" in content:\n",
    "                            content = content.split(\"\\r\")\n",
    "                            for con in content:\n",
    "                                contents.append(con)\n",
    "                        else:\n",
    "                            contents.append(content)\n",
    "                if len(contents) == 1:\n",
    "                    contents = \"\".join(contents)\n",
    "            else:\n",
    "                contents = list_cont[i].contents\n",
    "                contents = \"\".join(contents)\n",
    "                contents = formated(contents)\n",
    "\n",
    "            # 동일한 요소가 contents(list)에 들어있을 경우\n",
    "            if (\n",
    "                isinstance(contents, list)\n",
    "                and len(contents) == 2\n",
    "                and contents[0] == contents[1]\n",
    "            ):\n",
    "                contents = set(contents)\n",
    "                contents = \"\".join(contents)\n",
    "                contents = formated(contents)\n",
    "            # 정책의 항목 이름, 내용 연결\n",
    "            policy[list_tit[i].text] = contents\n",
    "        total_policy.append(policy)\n",
    "    return total_policy\n",
    "\n",
    "# 저장 경로 생성\n",
    "DATA_DIR = \"../data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# 정책 ID 수집\n",
    "URL = \"https://www.youthcenter.go.kr/youngPlcyUnif/youngPlcyUnifList.do?pageUnit=60&pageIndex=\"\n",
    "policy_id_list = get_ids_with_state(59, URL)\n",
    "print(f\"{len(policy_id_list)}개 정책 ID 크롤링 완료\")\n",
    "\n",
    "# 저장\n",
    "save_pickle(f\"{DATA_DIR}\", \"policy_id_list.pkl\", policy_id_list)\n",
    "print(\"policy_id_list 저장 완료\")\n",
    "\n",
    "# 정책 상세 정보 크롤링\n",
    "DETAIL_URL = \"https://www.youthcenter.go.kr/youngPlcyUnif/youngPlcyUnifDtl.do?bizId=\"\n",
    "params = {\n",
    "    \"title\": [\"h2\", \"doc_tit01 type2\"],\n",
    "    \"list_tit\": [\"div\", \"list_tit\"],\n",
    "    \"list_cont\": [\"div\", \"list_cont\"],\n",
    "}\n",
    "total_policy = crawling(policy_id_list, DETAIL_URL, params, cont_attrs=True)\n",
    "print(f\"{len(total_policy)}개 정책 상세 정보 크롤링 완료\")\n",
    "\n",
    "# 저장\n",
    "save_json(f\"{DATA_DIR}\", \"policy.json\", total_policy)\n",
    "print(\"policy.json 저장 완료\")\n",
    "\n",
    "# 삭제 항목 정의\n",
    "remove_keys = [\n",
    "    \"정책 번호\", \"신청 사이트\", \n",
    "    \"사업관련 참고 사이트 1\", \"사업관련 참고 사이트 2\", \"첨부파일\"\n",
    "]\n",
    "\n",
    "remove_values = [\n",
    "    \"제한없음\", \"\", \"-\", \"상관없음\", \"□제한없음\",\n",
    "    \"□ 제한없음\",\"- 제한없음\",\"-제한없음\"\n",
    "]\n",
    "\n",
    "# 삭제 함수 정의\n",
    "def remove_keys_from_data(data, keys):\n",
    "    if isinstance(data, list):\n",
    "        return [remove_keys_from_data(item, keys) for item in data]\n",
    "    elif isinstance(data, dict):\n",
    "        return {\n",
    "            key: remove_keys_from_data(value, keys)\n",
    "            for key, value in data.items()\n",
    "            if key not in keys\n",
    "        }\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def remove_values_from_data(data):\n",
    "    if isinstance(data, list):\n",
    "        return [remove_values_from_data(item) for item in data if item not in remove_values]\n",
    "    elif isinstance(data, dict):\n",
    "        return {\n",
    "            key: remove_values_from_data(value)\n",
    "            for key, value in data.items()\n",
    "            if value not in remove_values\n",
    "        }\n",
    "    else:\n",
    "        return data\n",
    "    \n",
    "# 불러오기 \n",
    "data = load_json(\"../data/policy.json\")\n",
    "\n",
    "# 삭제\n",
    "data_cleaned_keys = remove_keys_from_data(data, remove_keys)\n",
    "preprocess_data = remove_values_from_data(data_cleaned_keys)\n",
    "\n",
    "# 저장\n",
    "save_json(\"../data\",\"policy_result.json\", preprocess_data)\n",
    "\n",
    "print(\"policy_result.json 저장 완료\")\n",
    "\n",
    "# 불러오기\n",
    "data = load_json(\"../data/policy.json\")\n",
    "\n",
    "# 모든 텍스트 추출\n",
    "def text_from_json(data):\n",
    "    \"\"\"\n",
    "    JSON 데이터에서 모든 문자열을 추출.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    if isinstance(data, dict):\n",
    "        for value in data.values():\n",
    "            texts.extend(text_from_json(value))\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            texts.extend(text_from_json(item))\n",
    "    elif isinstance(data, str):\n",
    "        texts.append(data)\n",
    "    return texts\n",
    "\n",
    "# 단어 분리\n",
    "def text_to_word(text):\n",
    "    \"\"\"\n",
    "    텍스트를 정제하고 단어 단위로 분리.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)  # 특수문자 제거\n",
    "    words = text.split()  # 공백 기준으로 단어 분리\n",
    "    return words\n",
    "\n",
    "# 자주 등장하는 단어 찾기\n",
    "def get_frequent_words(words, threshold=100):\n",
    "    \"\"\"\n",
    "    단어 목록에서 자주 등장하는 단어를 찾음.\n",
    "    \"\"\"\n",
    "    word_counts = Counter(words)\n",
    "    frequent_words = [word for word, count in word_counts.items() if count >= threshold]\n",
    "    return frequent_words\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 불러오기\n",
    "    FILE_PATH = \"../data/policy_result.json\"\n",
    "    data = load_json(FILE_PATH)\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    texts = text_from_json(data)\n",
    "    \n",
    "    # 단어 분리\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        all_words.extend(text_to_word(text))\n",
    "    \n",
    "    # 50번 이상 등장하는 단어\n",
    "    threshold = 100\n",
    "    frequent_words = get_frequent_words(all_words, threshold)\n",
    "    \n",
    "    # 출력\n",
    "    print(\"[100번 이상 등장하는 단어]\")\n",
    "    for i in range(0, len(frequent_words), 10):\n",
    "        print(\", \".join(frequent_words[i:i + 10]))\n",
    "\n",
    "# 불러오기\n",
    "data = load_json(\"../data/policy_result.json\")\n",
    "\n",
    "# 불용어 \n",
    "stopwords = [\n",
    "    \"수행\", \"경우\", \"해당\", \"통하여\", \"대한\", \"관련\",\"등\", \"및\", \"또는\", \"중인\", \"통해\",\n",
    "    \"따라\", \"서비스\", \"제공\", \"프로그램\", \"참여\", \"따른\", \"대한\", \"해당\", \"관한\",\"이용\", \n",
    "    \"등을\", \"두고\"\n",
    "]\n",
    "\n",
    "# 제거 함수\n",
    "def remove_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # URL 제거\n",
    "        text = re.sub(r'\\bhttps?://[^\\s]*\\.kr\\b', '', text)\n",
    "        \n",
    "        # 특수기호 제거 (숫자, 한글, 영어 유지)\n",
    "        text = re.sub(r'[^가-힣a-zA-Z0-9\\s.~%]',' ', text)\n",
    "        \n",
    "        # 불용어 제거\n",
    "        for stopword in stopwords:\n",
    "            text = text.replace(stopword, '')\n",
    "        return text   \n",
    "    \n",
    "    return text\n",
    "\n",
    "# 데이터 처리\n",
    "def process_json(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: process_json(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [process_json(item) for item in data]\n",
    "    elif isinstance(data, str):\n",
    "        return remove_text(data)\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "cleaned_data = process_json(data)\n",
    "\n",
    "# 저장\n",
    "save_json(\"../data\",\"policy_result.json\",cleaned_data)\n",
    "print(\"policy_result.json 저장 완료\")\n",
    "\n",
    "# 불러오기\n",
    "data = load_json(\"../data/policy_result.json\")\n",
    "\n",
    "# 문자열 병합 \n",
    "def merge_values(item):\n",
    "    \"\"\"\n",
    "    리스트, 딕셔너리, 문자열을 하나의 문자열로 병합\n",
    "    \"\"\"\n",
    "    if isinstance(item, list):\n",
    "        return \" \".join(merge_values(sub_item) for sub_item in item)\n",
    "    elif isinstance(item, dict):\n",
    "        return \" \".join(f\"{key}: {merge_values(value)}\" for key, value in item.items())\n",
    "    elif isinstance(item, str):\n",
    "        return item.strip()\n",
    "    else:\n",
    "        return str(item)\n",
    "\n",
    "\n",
    "# 특정 키는 유지, 나머지는 병합\n",
    "def restructure_policy_data(data):\n",
    "    \"\"\"\n",
    "    '정책 이름', '기관', '요약', '정책 분야'는 유지하고 나머지는 '내용'에 병합\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            if isinstance(item, dict):\n",
    "                policy = {\n",
    "                    \"정책 이름\": item.get(\"정책 이름\", \"알 수 없음\"),\n",
    "                    \"기관\": item.get(\"기관\", \"알 수 없음\"),\n",
    "                    \"요약\": item.get(\"요약\", \"알 수 없음\"),\n",
    "                    \"정책 분야\": item.get(\"정책 분야\", \"알 수 없음\")\n",
    "                }\n",
    "\n",
    "                # '내용'에 나머지 항목 병합\n",
    "                remaining_content = [\n",
    "                    f\"{key}: {merge_values(value)}\"\n",
    "                    for key, value in item.items()\n",
    "                    if key not in [\"정책 이름\", \"기관\", \"요약\", \"정책 분야\"]\n",
    "                ]\n",
    "                policy[\"내용\"] = \" \".join(remaining_content)\n",
    "\n",
    "                result.append(policy)\n",
    "    return result\n",
    "\n",
    "\n",
    "# 실행\n",
    "restructured_data = restructure_policy_data(data)\n",
    "\n",
    "\n",
    "# 저장\n",
    "save_json(\"../data\", \"policy_result.json\", restructured_data)\n",
    "print(\"policy_result.json 저장 완료\")\n",
    "\n",
    "# 불러오기\n",
    "data = load_json(\"../data/policy_result.json\")\n",
    "\n",
    "# 지역 매핑 (정규표현식: 기관명에 포함된 지역명)\n",
    "region_patterns = {\n",
    "    r'경.*북.*': '경상북도',\n",
    "    r'경.*남.*': '경상남도',\n",
    "    r'강.*원.*': '강원도',\n",
    "    r'전.*북.*': '전라북도',\n",
    "    r'전.*남.*': '전라남도',\n",
    "    r'충.*북.*': '충청북도',\n",
    "    r'충.*남.*': '충청남도',\n",
    "    r'제.*주.*': '제주특별자치도',\n",
    "    r'서.*울.*': '서울특별시',\n",
    "    r'부.*산.*': '부산광역시',\n",
    "    r'대.*구.*': '대구광역시',\n",
    "    r'대.*전.*': '대전광역시',\n",
    "    r'광.*주.*': '광주광역시',\n",
    "    r'울.*산.*': '울산광역시',\n",
    "    r'인.*천.*': '인천광역시',\n",
    "    r'세.*종.*': '세종특별자치시'\n",
    "}\n",
    "\n",
    "# 데이터 변환\n",
    "def replace_institution_with_region(data):\n",
    "    \"\"\"\n",
    "    '기관'을 '지역'으로 키를 대체하고 순서를 유지합니다.\n",
    "    \"\"\"\n",
    "    for policy in data:\n",
    "        if \"기관\" in policy:\n",
    "            institution = policy[\"기관\"]\n",
    "            region = '전국'  # 기본값 설정\n",
    "            \n",
    "            # 기관명에서 지역 매칭\n",
    "            for pattern, mapped_region in region_patterns.items():\n",
    "                if re.search(pattern, institution):\n",
    "                    region = mapped_region\n",
    "                    break\n",
    "            \n",
    "            # '기관'을 '지역'으로 대체 (순서 유지)\n",
    "            updated_policy = {}\n",
    "            for key, value in policy.items():\n",
    "                if key == \"기관\":\n",
    "                    updated_policy[\"지역\"] = region\n",
    "                else:\n",
    "                    updated_policy[key] = value\n",
    "            \n",
    "            # 기존 항목을 새로운 항목으로 교체\n",
    "            policy.clear()\n",
    "            policy.update(updated_policy)\n",
    "\n",
    "# 실행행\n",
    "replace_institution_with_region(data)\n",
    "\n",
    "# 저장\n",
    "save_json(\"../data\", \"policy_result.json\", data)\n",
    "print(\"policy_result.json 저장 완료\")\n",
    "\n",
    "# 불러오기\n",
    "data = load_json(\"../data/policy_result.json\")\n",
    "\n",
    "# 띄어쓰기 제거 \n",
    "def remove_spaces(data):\n",
    "    \"\"\"\n",
    "    모든 Key에서 띄어쓰기를 제거합니다.\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        return [remove_spaces(item) for item in data]\n",
    "    elif isinstance(data, dict):\n",
    "        return {key.replace(\" \", \"\"): remove_spaces(value) for key, value in data.items()}\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# 마지막 2글자 삭제 \n",
    "def modify_policy_field(data):\n",
    "    \"\"\"\n",
    "    \"정책분야\"의 Value 마지막 2글자를 삭제합니다.\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            modify_policy_field(item)\n",
    "    elif isinstance(data, dict):\n",
    "        if \"정책분야\" in data and isinstance(data[\"정책분야\"], str):\n",
    "            data[\"정책분야\"] = data[\"정책분야\"][:-2]  # 마지막 2글자 제거\n",
    "        for key, value in data.items():\n",
    "            modify_policy_field(value)\n",
    "\n",
    "# 실행\n",
    "data = remove_spaces(data)\n",
    "modify_policy_field(data)\n",
    "\n",
    "# 저장\n",
    "save_json(\"../data\", \"policy_result.json\", data)\n",
    "print(\"policy_result.json 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e702f1-6266-4ea9-8bce-db498a3e7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "DIRECTORY_PATH = r\"..\\data\"\n",
    "PERSIST_DIRECTORY = r\"..\\data\\vector_store\\policy\"\n",
    "COLLECTION_NAME = \"policy\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "TOKENIZED_DATA_PATH = os.path.join(DIRECTORY_PATH, \"policy_result.json\")\n",
    "\n",
    "# JSON 데이터 불러오기 함수\n",
    "data = load_json(TOKENIZED_DATA_PATH)\n",
    "\n",
    "# Document 객체로 변환\n",
    "documents = []\n",
    "for policy in data:  # 리스트의 각 항목 순회\n",
    "    if isinstance(policy, dict):  # 각 항목이 딕셔너리인지 확인\n",
    "    # 필요한 데이터를 병합하여 page_content 생성\n",
    "        merged_text = \" \".join([\n",
    "            policy.get(\"정책이름\", \"\"), \n",
    "            policy.get(\"요약\", \"\"), \n",
    "            policy.get(\"내용\", \"\")\n",
    "        ])\n",
    "\n",
    "    # Document 객체 생성 및 추가\n",
    "        documents.append(\n",
    "            Document(\n",
    "                page_content=merged_text,\n",
    "                metadata={\n",
    "                    \"name\": policy.get(\"정책이름\", \"알 수 없음\"), \n",
    "                    \"region\": policy.get(\"지역\", \"알 수 없음\"),\n",
    "                    \"category\": policy.get(\"정책분야\", \"알 수 없음\"),\n",
    "                    \"source\": TOKENIZED_DATA_PATH,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Vector Store 생성/로드\n",
    "embedding_model = OpenAIEmbeddings(model=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# Vector Store 생성/로드\n",
    "if os.path.exists(PERSIST_DIRECTORY):\n",
    "    vector_store = Chroma(\n",
    "        persist_directory=PERSIST_DIRECTORY,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_model,\n",
    "    )\n",
    "else:\n",
    "    os.makedirs(PERSIST_DIRECTORY, exist_ok=True)\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_model,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        persist_directory=PERSIST_DIRECTORY,\n",
    "    )\n",
    "\n",
    "# 저장된 파일 확인\n",
    "saved_files = os.listdir(PERSIST_DIRECTORY)\n",
    "\n",
    "# Retriever 설정 - 검색 설정\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"fetch_k\": 10,\n",
    "        \"lambda_mult\": 0.2,\n",
    "    },\n",
    ")\n",
    "\n",
    "# db 검색 tool\n",
    "@tool\n",
    "def search_policy(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Vector Store에 저장된 청년 지원 정책과 해당 정책의 정보를 검색한다.\n",
    "    이 도구는 청년 지원 정책 관련 질문에 대해 실행한다.\n",
    "    \"\"\"\n",
    "    result = retriever.invoke(query)\n",
    "    return result if result else [Document(page_content=\"검색 결과가 없습니다.\")]\n",
    "\n",
    "# web 검색 tool\n",
    "@tool\n",
    "def search_web(query: str) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Web에서 청년 지원 정책과 해당 정책의 정보를 검색한다.\n",
    "    이 도구는 청년 지원 정책 관련 질문에 대해 실행한다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tavily_search = TavilySearchResults(max_results=2)\n",
    "        result = tavily_search.invoke(query)\n",
    "        if result:\n",
    "            return [\n",
    "                Document(\n",
    "                    page_content=item.get(\"content\", \"\"),\n",
    "                    metadata={\"title\": item.get(\"title\", \"\")},\n",
    "                )\n",
    "                for item in result\n",
    "            ]\n",
    "        else:\n",
    "            return [Document(page_content=\"검색 결과가 없습니다.\")]\n",
    "    except Exception as e:\n",
    "        return [Document(page_content=f\"오류 발생: {str(e)}\")]\n",
    "\n",
    "# 사용자 정의 비속어 리스트 로드 함수 \n",
    "def load_custom_profanity(): \n",
    "    \"\"\" \n",
    "    사용자 정의 비속어 리스트를 로드하여 better-profanity에 추가합니다. \n",
    "    \"\"\" \n",
    "    custom_words_path = r\"..\\data\\fword_list_KOR.txt\"  # 비속어 리스트 파일 경로 \n",
    "    try: \n",
    "        with open(custom_words_path, \"r\", encoding=\"utf-8\") as f: \n",
    "            # 사용자 정의 비속어 리스트를 set으로 저장\n",
    "            custom_words = set(line.strip() for line in f.readlines()) \n",
    "        profanity.add_censor_words(custom_words)  # 사용자 정의 비속어 추가 \n",
    "        return custom_words  # 추가: 비속어 리스트 반환\n",
    "    except FileNotFoundError: \n",
    "        print(f\"비속어 리스트 파일이 존재하지 않습니다: {custom_words_path}\") \n",
    "        return set()  # 추가: 비속어 리스트가 없을 경우 빈 set 반환\n",
    "\n",
    "# 비속어 감지 함수\n",
    "def is_inappropriate_message(message):\n",
    "    \"\"\" \n",
    "    better-profanity와 사용자 정의 리스트를 사용해 비속어를 감지하는 함수. \n",
    "    \"\"\" \n",
    "    custom_profanity_set = load_custom_profanity()  # 사용자 정의 비속어 리스트 로드 \n",
    "    \n",
    "    # 메시지를 단어 단위로 나누어 비속어 감지\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in custom_profanity_set:  # 사용자 정의 비속어 리스트 확인\n",
    "            return True\n",
    "    return profanity.contains_profanity(message)  # better-profanity 확인\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "# 대화 기록 저장 및 불러오기 \n",
    "def save_conversation_to_file(history, filename=\"conversation_log.json\"):\n",
    "    session_data = {\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"history\": history,\n",
    "    }\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        data = {\"sessions\": []}\n",
    "    data[\"sessions\"].append(session_data)\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# 대화 기록 불러오기 함수\n",
    "def load_conversations_from_file(filename=\"conversation_log.json\"):\n",
    "    \"\"\"\n",
    "    대화 기록을 파일에서 불러옵니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        return data.get(\"sessions\", [])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{filename} 파일이 존재하지 않습니다.\")\n",
    "        return []\n",
    "\n",
    "# 히스토리를 JSON 직렬화 가능하게 변환\n",
    "def serialize_history(history):\n",
    "    serialized = []\n",
    "    for message in history:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            serialized.append({\"type\": \"human\", \"content\": message.content})\n",
    "        elif isinstance(message, AIMessage):\n",
    "            serialized.append({\"type\": \"ai\", \"content\": message.content})\n",
    "        else:\n",
    "            serialized.append({\"type\": \"unknown\", \"content\": str(message)})\n",
    "    return serialized\n",
    "\n",
    "# JSON 데이터를 히스토리로 역변환\n",
    "def deserialize_history(serialized_history):\n",
    "    history = []\n",
    "    for message in serialized_history:\n",
    "        if message[\"type\"] == \"human\":\n",
    "            history.append(HumanMessage(content=message[\"content\"]))\n",
    "        elif message[\"type\"] == \"ai\":\n",
    "            history.append(AIMessage(content=message[\"content\"]))\n",
    "    return history\n",
    "\n",
    "# 세션 선택\n",
    "def select_session(conversations):\n",
    "    if not conversations:\n",
    "        print(\"저장된 대화 세션이 없습니다. 새 세션이 시작됩니다.\")\n",
    "        return None\n",
    "\n",
    "    print(\"=== 기존 대화 세션 목록 ===\")\n",
    "    for idx, session in enumerate(conversations):\n",
    "        print(f\"{idx + 1}. {session['title']} ({session['date']})\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(f\"세션 번호를 선택하세요 (1-{len(conversations)}) 또는 'new'를 입력하여 새 세션 시작: \").strip()\n",
    "        if choice == \"new\":\n",
    "            return None\n",
    "        try:\n",
    "            idx = int(choice) - 1\n",
    "            if 0 <= idx < len(conversations):\n",
    "                return conversations[idx]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        print(\"잘못된 입력입니다. 다시 시도하세요.\")\n",
    "\n",
    "# 사이드바 출력 함수\n",
    "def display_sidebar(conversations):\n",
    "    \"\"\"\n",
    "    대화 목록을 사이드바 형태로 출력합니다.\n",
    "    \"\"\"\n",
    "    print(\"=== 대화 히스토리 ===\")\n",
    "    for idx, convo in enumerate(conversations):\n",
    "        print(f\"{idx + 1}. {convo['title']} ({convo['date']})\")\n",
    "\n",
    "# Document 객체를 dict로 변환\n",
    "def serialize_documents(documents):\n",
    "    if isinstance(documents, list):\n",
    "        if all(isinstance(doc, Document) for doc in documents):\n",
    "            return [\n",
    "                {\"page_content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "                for doc in documents\n",
    "            ]\n",
    "        elif all(isinstance(doc, dict) for doc in documents):\n",
    "            return documents\n",
    "    return []\n",
    "\n",
    "# LOG 저장 함수\n",
    "def save_json(file_path: str, data: list):\n",
    "    \"\"\"\n",
    "    데이터를 json 파일로 저장.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)  # 디렉토리 생성\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# LLM 구성\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        (\n",
    "            \"ai\",\n",
    "            dedent(\n",
    "                \"\"\"\n",
    "        당신은 유능한 청년지원정책 추천 전문 AI 챗봇입니다.\n",
    "        주요 목표는 사용자의 요청에 따라 알맞는 청년지원정책을 추천하는 것입니다.\n",
    "        다음은 답변을 작성하기 위한 지침(guidelines)입니다:\n",
    "        1. 주어진 context(데이터 및 검색 결과)를 바탕으로만 대답해주세요.\n",
    "        2. 모든 답변은 학습된 정책 데이터를 바탕으로 사용자가 물어본 질문에 대한 정확한 정보만 작성하세요.\n",
    "        3. 답변에 불필요한 정보는 제공하지 마세요. \n",
    "        4. 해당 데이터에 없는 내용은 검색해서 대답세요. 다만, 검색 도구(TavilySearch 등)에서도 찾을 수 없는 경우, 답변을 추측하거나 임의로 생성하지 말고 \"잘 모르겠습니다.\"라고 답변하세요.검색으로도 정보를 찾을 수 없을 경우 답변을 추측하거나 임의로 생성하지말고, \"잘 모르겠습니다.\"라고 답변하세요.\n",
    "        5. 답변은 체계적이고, 비전문가 사용자도 이해하기 쉽게 답변을 작성하세요.\n",
    "        6. 항상 최신의 정확한 정보를 제공하기 위해 노력하세요.\n",
    "        7. 질문을 완전히 이해하지 못할 경우, 구체적인 질문을 다시 받을 수 있도록 사용자에게 유도 질문을 하세요.     \n",
    "        8. 답변 스타일은 간결하고 논리적으로 작성하세요. 필요시, 리스트 형식으로 정리하세요.\n",
    "        \n",
    "        위 지침을 따라 사용자의 요청에 맞는 적절한 청년지원정책 정보를 제공합니다.\n",
    "        {context}\n",
    "    \"\"\"\n",
    "            ),\n",
    "        ),\n",
    "        MessagesPlaceholder(\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "# agent 구성\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=model, tools=[search_policy, search_web], prompt=prompt_template\n",
    ")\n",
    "\n",
    "runnable = (\n",
    "    {\n",
    "        \"context\": RunnableLambda(lambda x: retriever.invoke(x[\"question\"])),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"history\": itemgetter(\"history\"),\n",
    "    }\n",
    "    | prompt_template\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain = RunnableWithMessageHistory(\n",
    "    runnable=runnable,\n",
    "    get_session_history=lambda session_id: memory.chat_memory,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "toolkit = [search_policy, search_web]\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True)\n",
    "\n",
    "# 로그 저장 경로\n",
    "LOG_DIR = \"../data\"\n",
    "LOG_FILE = \"../data/response_log.json\"\n",
    "\n",
    "# 메인 로직\n",
    "def main():\n",
    "    # 기존 대화 불러오기\n",
    "    filename = \"conversation_log.json\"\n",
    "    conversations = load_conversations_from_file(filename)\n",
    "\n",
    "    # 세션 선택\n",
    "    session = select_session(conversations)\n",
    "    if session:\n",
    "        print(f\"선택된 세션: {session['title']}\")\n",
    "        history = deserialize_history(session[\"history\"])\n",
    "    else:\n",
    "        print(\"새로운 대화 세션이 시작됩니다.\")\n",
    "        history = []\n",
    "    \n",
    "    # 사용자 질문 입력\n",
    "    while True:\n",
    "        query = input(\"질문을 입력하세요: \").strip()\n",
    "        if not query:  # 입력값이 비었을 경우\n",
    "            print(\"유효한 질문을 입력하세요.\")\n",
    "            continue\n",
    "    \n",
    "        if is_inappropriate_message(query):  # 비속어 감지\n",
    "            print(\"부적절한 메시지가 감지되었습니다. 다시 시도하세요.\")\n",
    "        else:\n",
    "            break  # 비속어가 없는 경우 루프 종료\n",
    "\n",
    "    # 히스토리 업데이트\n",
    "    history.append(HumanMessage(content=query))\n",
    "\n",
    "    # 답변 생성 (예: 에이전트 호출)\n",
    "    result_from_db = search_policy.invoke(query)\n",
    "    result_from_web = search_web.invoke(query)\n",
    "\n",
    "    def combine_search_results(result_from_db: list, result_from_web: list) -> str:\n",
    "        combined_context = [\n",
    "            \"저장된 데이터에서 찾은 정보:\\n\",\n",
    "            *[doc.page_content for doc in result_from_db],\n",
    "            \"실시간 web 검색에서 확인된 정보:\\n\",\n",
    "        ]\n",
    "        if result_from_web:\n",
    "            combined_context.extend(\n",
    "                [f\"[{idx}] {doc.metadata.get('title', '제목 없음')}: {doc.page_content}\"\n",
    "                 for idx, doc in enumerate(result_from_web, start=1)]\n",
    "            )\n",
    "        else:\n",
    "            combined_context.append(\"web 검색 결과가 없습니다.\")\n",
    "        return \"\\n\".join(combined_context)\n",
    "    \n",
    "    combined_context = combine_search_results(result_from_db, result_from_web)\n",
    "\n",
    "    # LLM 입력 메세지 구성\n",
    "    final_input = {\n",
    "        \"context\": combined_context,\n",
    "        \"question\": query,\n",
    "        \"history\": history,  # 메모리에서 불러온 이전 대화 이력을 사용\n",
    "    }\n",
    "    \n",
    "    # 최종 응답 생성\n",
    "    final_response = agent_executor.invoke(final_input)\n",
    "    print(final_response[\"output\"])\n",
    "    history.append(AIMessage(content=final_response[\"output\"]))\n",
    "\n",
    "    # 대화 저장\n",
    "    if session:\n",
    "        session[\"history\"] = serialize_history(history)\n",
    "    else:\n",
    "        new_session = {\n",
    "            \"title\": f\"{query[:50]} ({datetime.now().strftime('%Y-%m-%d')})\",\n",
    "            \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"history\": serialize_history(history),\n",
    "        }\n",
    "        conversations.append(new_session)\n",
    "\n",
    "    # JSON 저장\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump({\"sessions\": conversations}, file, ensure_ascii=False, indent=4)\n",
    "    print(f\"대화가 {filename}에 저장되었습니다.\")\n",
    "\n",
    "    # log 저장\n",
    "    log = {\n",
    "        \"question\": query.strip(),\n",
    "        \"db_result\": serialize_documents(result_from_db),\n",
    "        \"web_result\": serialize_documents(result_from_web),\n",
    "        \"final_answer\": final_response[\"output\"]\n",
    "    }\n",
    "    save_json(LOG_FILE, log)\n",
    "    print(f\"log가 {LOG_FILE}에 저장되었습니다.\")\n",
    "\n",
    "# 실행 코드\n",
    "main()\n",
    "\n",
    "# 대화 기록 불러오기 및 사이드바 출력\n",
    "conversations = load_conversations_from_file()\n",
    "display_sidebar(conversations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
